{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"신경망2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyONPVBGsNWQtAeKwhHOSvE+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2-TI3pOHm48x","colab_type":"text"},"source":["1. 데이터 로딩\n","2. 하이퍼파라미터 설정하기\n","3. 신경망 & 출력층 설계 및 구현\n","4. 미니배치 구성 & 학습\n","5. 기울기 (gradient) 계산\n","6. 가중치 업데이트\n","7. 학습 경과 기록하기 (loss function)"]},{"cell_type":"code","metadata":{"id":"qr0B0VdjXa9E","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599702144067,"user_tz":-540,"elapsed":610,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}}},"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"JwPgw4zbrVMr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"status":"ok","timestamp":1599702165970,"user_tz":-540,"elapsed":902,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}},"outputId":"c18a8511-1fbd-4aab-b763-fc39c00222a2"},"source":["plt.imshow(x_train[0])"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fe049339a58>"]},"metadata":{"tags":[]},"execution_count":6},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"wUHhVUKyqysQ","colab_type":"text"},"source":["1. 데이터로딩"]},{"cell_type":"code","metadata":{"id":"0F_WQdXKqRQ5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1599706371437,"user_tz":-540,"elapsed":1288,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}},"outputId":"331ef232-68ff-4431-cd51-be5dcf73c489"},"source":["mnist = tf.keras.datasets.mnist\n","(x_train,y_train),(x_test,y_test) = mnist.load_data()\n","# 정규화과정, 픽셀의 이미지 표현범위가 0 ~ 255이므로 모두 0~1 의 값으로 만들기 위해\n","x_train,x_test = x_train/255.0,x_test/255.0\n","# 1차원 배열로 전환\n","x_test_flatten = x_test.reshape([x_test.shape[0],-1])\n","x_train_flatten = x_train.reshape([x_train.shape[0],-1])\n","print(x_test.shape)\n","print(x_test_flatten.shape)\n","t_train = y_train"],"execution_count":10,"outputs":[{"output_type":"stream","text":["(10000, 28, 28)\n","(10000, 784)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5ZZbQEom9iEf","colab_type":"text"},"source":["2층 신경망 클래스 정의"]},{"cell_type":"code","metadata":{"id":"YnOe5U2eDFPd","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599709238447,"user_tz":-540,"elapsed":1659,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}}},"source":["def sigmoid(x):\n","  return 1 / ( 1 + np.exp(-x))\n","def softmax(a):\n","  exp_a = np.exp(a)\n","  sum_exp_a = np.sum(exp_a)\n","  y = exp_a / sum_exp_a\n","  return y\n","def cross_entropy_error(y,t):\n","  if y.ndim == 1: #1차원이면 2차원으로 만들어 주는 과정.\n","    t= t.reshape(1,t.size)\n","    y= y.reshape(1,y.size)\n","\n","    batch_size = y.shape[0]\n","    return -np.sum(np.log(y[np.arange(batch_size),t]+1e-7)) / batch_size"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvdnhjvD9TW5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599709639986,"user_tz":-540,"elapsed":659,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}}},"source":["class TwoLayerNet:\n","  def __init__(self,input_size,hidden_size,output_size,weight_init_std=0.01):\n","    # 가중치 초기화\n","    self.params = {}\n","    self.params['w1'] = weight_init_std * np.random.randn(input_size,hidden_size)\n","    self.params['w2'] = weight_init_std * np.random.randn(hidden_size,output_size)\n","    self.params['b1'] = np.zeros(hidden_size)\n","    self.params['b2'] = np.random.randn(output_size)\n","\n","  def predict(self,x):\n","    w1,w2 = self.params['w1'],self.params['w2']\n","    b1,b2 = self.params['b1'], self.params['b2']\n","    \n","    a1 = np.dot(x,w1) + b1\n","    z1 = sigmoid(a1)\n","    \n","    a2 = np.dot(z1,w2) + b2\n","    y = softmax(a2)\n","    return y\n","  # 손실 함수,  x :입력데이터, t: 정답 데이터\n","  def loss(self,x,t):\n","    y = self.predict(x)\n","    loss = cross_entropy_error(y,t)\n","    return loss\n","  \n","  def accuracy(self,x,y):\n","    y = self.predict(x)\n","    y = np.argmax(y,axis=1) # 최대값을 불러옴\n","    t = np.argmax(t,axis=1)\n","    accuracy = np.sum(y==t) / float(x.shape[0])\n","\n","    return accuracy\n","\n","  def numerical_gradient(self,x,t):\n","    loss_w = lambda w:self.loss(x,t)\n","\n","    grads = {}\n","    grads['w1'] = numerical_gradient(loss_w,self.params['w1'])\n","    grads['w2'] = numerical_gradient(loss_w,self.params['w2'])\n","    grads['b1'] = numerical_gradient(loss_w,self.params['b1'])\n","    grads['b2'] = numerical_gradient(loss_w,self.params['b2'])\n","\n","    return grads"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m-FU5-o7rMOs","colab_type":"text"},"source":["2. 하이퍼 파라미터 설정"]},{"cell_type":"code","metadata":{"id":"9PHr3T7MqusB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599709641165,"user_tz":-540,"elapsed":492,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}}},"source":["iters_num = 10000 # 반복횟수\n","train_size = x_train_flatten.shape[0] # train data의 사이즈 10000\n","batch_size = 100 # 미니배치 크기.\n","learning_rate = 0.1 # 학습률 "],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u92MLLYft0uu","colab_type":"text"},"source":["3. 신경망 구현"]},{"cell_type":"code","metadata":{"id":"p3P2Ngz5t2TE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599709643004,"user_tz":-540,"elapsed":584,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}}},"source":["def predict(network,x):\n","  w1,w2 = network['w1'],network['w2']\n","  b1,b2 = network['b1'],network['b2']\n","\n","  # 입력층 -> 은닉층(1층,2층) -> 출력층\n","  a1 = np.dot(x,w1) + b1\n","  z1 = sigmoid(a1)\n","  a2 = np.dot(z1,w2) + b2\n","  # 분류문제이므로 soft max 함수를 사용한다.\n","  y = softmax(a2)\n","  return y"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p4fgHds-wIYG","colab_type":"text"},"source":["4. 미니배치 구성 & 학습\n","  - \n"]},{"cell_type":"code","metadata":{"id":"O386tYOk35gx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599709644891,"user_tz":-540,"elapsed":563,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}}},"source":["import numpy as np"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"jwwBSO6j3sG1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599709645626,"user_tz":-540,"elapsed":371,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}}},"source":["def numerical_gradient1(f,x):\n","  h = 1e-4 # 0.0001\n","  grad = np.zeros_like(x) # x랑 모양이 똑같은데 0 으로 다 채워져 있는\n","  # 각 자리에 gradient 값을 저장하기 위해\n","\n","  for idx in range(x.shape[0]):\n","    tmp_val = x[idx] # 원본값 저장\n","\n","    #y증가량 / x증가량 = 기울기 \n","    # y증가량 : f(x+h) - f(x-h)\n","    # f(x+h)\n","    x[idx] = tmp_val + h\n","    fxh1 = f(x)\n","    # f(x-h)\n","    x[idx] = tmp_val -h \n","    fxh2 = f(x)\n","    # gradient 값 저장.\n","    grad[idx] = (fxh1-fxh2) / (2*h)\n","    x[idx] = tmp_val\n","    \n","    return grad"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"NYBDjIbRwIBv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"status":"error","timestamp":1599709646778,"user_tz":-540,"elapsed":579,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}},"outputId":"aefd9b14-10b3-4d40-d91f-7fd8021893f9"},"source":["# 네트워크 \n","network = TwoLayerNet(input_size=784,hidden_size=50,output_size=10)\n","\n","# 미니배치 구성\n","\n","train_loss_list = []\n","\n","# 학습할 땐 batch_size 만큼 뽑아서 사용\n","for i in range(iters_num):\n","  # 미니배치 구성\n","  batch_mask = np.random.choice(train_size,batch_size)\n","  # batch input\n","  x_batch = x_train_flatten[batch_mask]\n","  # 정답 label\n","  t_batch = t_train[batch_mask]\n","\n","  # 기울기 계산\n","  grad = network.numerical_gradient(x_batch,t_batch)\n","\n","  # 가중치 업데이트.\n","  for key in ('w1','w2','b1','b2'):\n","    network.params[key] -= learning_rate * grad[key]\n","\n","  # 학습 경과 기록 (손실함수)\n","\n","  loss = network.loss(x_batch,t_batch)\n","  train_loss_list.append(loss)\n","  print(loss)"],"execution_count":38,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-c24597805f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# 기울기 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# 가중치 업데이트.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-877475cbc62b>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-87dc013f45ff>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfxh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# gradient 값 저장.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfxh1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfxh2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'NoneType'"]}]},{"cell_type":"code","metadata":{"id":"3jfdxz8AwS_X","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}