{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"오차역전파법.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO9Zk0Mr5irXQ6vObZTdHSz"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"YhdY1Ty3-erV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599723942340,"user_tz":-540,"elapsed":730,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}}},"source":["#오차역전법"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFcWhXT1-hzn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599724540168,"user_tz":-540,"elapsed":610,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}}},"source":["# 계산 그래프에서 사용 되는 곱셈 노드와 덧셈노드를 구현\n","class MulLayer:\n","  def __init__(self):\n","    self.x = None\n","    self.y = None\n","\n","  def forward(self,x,y):\n","    self.x = x\n","    self.y = y\n","    out = x*y\n","    return out\n","\n","  def backward(self,dout):\n","    dx = dout * self.y\n","    dy = dout * self.x\n","\n","    return dx,dy\n","\n","  # 덧셈 노드\n","class AddLayer:\n","  def __init__(self):\n","    pass\n","  def forward(self,x,y):\n","    out = x+y\n","    return out\n","\n","  def backward(self,dout):\n","    dx = dout * 1\n","    dy = dout * 1\n","    return dx,dy\n","    "],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_tvPVNOAiCo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599724753031,"user_tz":-540,"elapsed":762,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}}},"source":["apple = 100\n","apple_num = 2 \n","tax = 1.1\n","\n","# 노드 정의\n","mul_apple_layer = MulLayer()\n","mul_tax_layer = MulLayer()\n","\n","# forwarding\n","apple_price = mul_apple_layer.forward(apple,apple_num)\n","price = mul_tax_layer.forward(apple_price,tax)\n","\n","# backward\n","dprice = 1 # 가격의증가분/가격의증가분\n","dapple_price,dtax = mul_tax_layer.backward(dprice)\n","dapple,dapple_num = mul_apple_layer.backward(dapple_price)\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"aMvQ98LxA0aO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1599724835255,"user_tz":-540,"elapsed":572,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}},"outputId":"6cd90350-ba19-4369-e252-59363c44541c"},"source":["print(int(price))\n","print(dapple_price,dtax)\n","print(dapple,dapple_num)\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["220\n","1.1 200\n","2.2 110.00000000000001\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1KS9hNpbB88i","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599725771994,"user_tz":-540,"elapsed":583,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}}},"source":["# affine \n","class Affine:\n","  def __init__(self,w,b):\n","    self.w = w\n","    self.b = b\n","    self.x = None\n","    self.dw = None\n","    self.db = None\n","  def forward(self,x):\n","    self.x=x\n","    out = np.dot(x,self.w)+self.b\n","    return out\n","  def backward(self,dout):\n","    dx = np.dot(dout,self.w.T)\n","    self.dw = np.dot(self.x.T,dout)\n","    self.db = np.sum(dout,axis = 0)\n","    return dx"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"dWpEd0NTFhmu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599726037930,"user_tz":-540,"elapsed":544,"user":{"displayName":"Hayoung Lee","photoUrl":"","userId":"03144357786308456738"}}},"source":["class SoftmaxWithLoss:\n","  def __init__(self):\n","    self.loss = None\n","    self.y = None\n","    self.t = None\n","\n","  def forward(self,x,t):\n","    self.t =t\n","    self.y = softmax(x)\n","    self.loss = cross_entropy_error(t,y)\n","    return self.loss\n","\n","  def backward(self,dout=1):\n","    batch_size = self.t.shape[0]\n","    dx = (self.y-self.t)  / batch_size\n","    return dx\n","    \n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"VHW-OSmkGiku","colab_type":"code","colab":{}},"source":["# 오차 역전파법을 이용한 2층짜리 network\n","class TwoLayerNet:\n","  def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n","    # 가중치 초기화 \n","    self.params = {}\n","    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n","    self.params['b1'] = np.zeros(hidden_size)\n","    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","    self.params['b2'] = np.zeros(output_size)\n","\n","    # 계층 생성\n","    self.layers = OrderedDict() # 순서가 있는 딕셔너리\n","    self.layers['Affine1'] = Affine(self.params['w1'],self.params['b1'])\n","    self.layers['Relu1'] = Relu()\n","    self.layers['Affine2'] = Affine(self.params['w2'],self.params['b2'])\n","    \n","    self.lastlayer = SoftmaxWithLoss()\n","\n","  def predict(self,x):\n","    for layer in self.layers.values():\n","      x = layer.forward(x)\n","    \n","    return x\n","\n","  def loss(self,x,t):\n","    y = self.predict(x)\n","    return self.lastlayer.forward(y,t)\n","\n","  def accuracy(self, x, t):\n","    y = self.predict(x)\n","    y = np.argmax(y, axis=1)\n","    t = np.argmax(t, axis=1)\n","\n","    accuracy = np.sum(y==t) / float(x.shape[0])\n","    return accuracy\n","\n","  # x : 입력 데이터, t : 정답 레이블\n","  def numerical_gradient(self, x, t):\n","    loss_W = lambda W: self.loss(x, t)\n","    \n","    grads = {}\n","    grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n","    grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n","    grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n","    grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n","    \n","    return grads\n","\n","  def gradient(self,x,t):\n","    # 순전파\n","    self.loss(x,t)\n","\n","    # 역전파\n","    dout = 1 \n","    dout = self.lastlayer.backward(dout)\n","\n","    layers = list(self.layers.values())\n","    layers.revers()\n","\n","    for layer in layers:\n","      dout = layer.backward(dout)\n","\n","      grads = {}\n","      grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n","      grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n","      grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n","      grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n","    \n","    return grads\n"],"execution_count":null,"outputs":[]}]}